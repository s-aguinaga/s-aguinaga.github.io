<!DOCTYPE HTML>

<!-- 
Strata by HTML5 UP
html5up.net | @n33co
Free for personal and commercial use under the CCA 3.0 license (html5up.net/license)
-->
<html>
	<head>
		<title>Neural Network Architectures &middot; Sal Aguinaga</title>
		<meta charset="utf-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1" />
		<meta name="author" content="Sal Aguinaga">
    	<meta name="description" content="I&#39;m drowning in the world&#39;s data!">
    	<meta http-equiv="content-language" content="en-us" />

		<meta name="generator" content="Hugo 0.30.2" />

		<!--[if lte IE 8]><script src='{{ .Site.BaseURL }}js/ie/html5shiv.js'></script><![endif]-->
		<link rel="stylesheet" href="//maxcdn.bootstrapcdn.com/font-awesome/4.5.0/css/font-awesome.min.css" type="text/css">
		<link rel="stylesheet" href="http://s-aguinaga.github.io/css/main.css" />
		<!--[if lte IE 8]><link rel='stylesheet' href='{{ .Site.BaseURL }}/css/ie8.css' /><![endif]-->

		
	</head>

	<body id="top">
		<!-- Header -->
<header id="header">
	<a href="http://s-aguinaga.github.io/" class="image avatar"><img src="http://s-aguinaga.github.io/images/avatar.jpg" alt="" /></a>
	
		<h1>PhD candidate, Department of Computer Science and Engineering at the <a href="http://cse.nd.edu">University of Notre Dame</a>.</h1>
	

	
		<nav id="sidebar">
			<ul>
			
				<li><a href="http://s-aguinaga.github.io/post/">Blog</a></li>
			
				<li><a href="http://s-aguinaga.github.io/">Home</a></li>
			
			</ul>
		</nav>
	
</header>


		<!-- Main -->
		<div id="main">
			
	<h1>Neural Network Architectures</h1>
	<span>
	    <i class="fa fa-calendar"></i>&nbsp;&nbsp;
	    <time datetime="2017-08-09 09:19:15 -0500 -0500">2017-08-09</time>&nbsp;&nbsp;

	    
	        
	        
	    

	    
	       
	       
	    
	</span>

	<p>
	    <p>This projects aims to examine the complexity of neural network architectures to leverage structure
that improves the training phase.</p>

<p></p>

<h1 id="notebook">Notebook</h1>

<p>My notes on many things ML and DL</p>

<h2 id="conferences">Conferences</h2>

<ul>
<li>International Conference on Learning Representations
2017 (April 24 - 26, 2017)`</li>
<li>AAAI (2 – 7 February  –  New Orleans, Louisiana, USA)</li>
</ul>

<h2 id="argonne-ml">Argonne ML</h2>

<ul>
<li>NN Zoo</li>
<li>NEURAL ARCHITECTURE SEARCH WITH REINFORCEMENT LEARNING,
Barret Zoph∗, Quoc V. Le (barretzoph, qvl@google.com)</li>
</ul>

<h2 id="network-architectures">Network Architectures</h2>

<p>-[] NEURAL ARCHITECTURE SEARCH WITH REINFORCEMENT LEARNING
        <a href="https://openreview.net/pdf?id=r1Ue8Hcxg">https://openreview.net/pdf?id=r1Ue8Hcxg</a>
-   _ <a href="http://wikicoursenote.com/wiki/Deep_Convolutional_Neural_Networks_For_LVCSR">Deep Convolutional Neural Networks For LVCSR</a></p>

<ul>
<li>[] Designing Neural Network Architectures using Reinforcement Learning</li>
<li>[] Making Neural Programming Architectures Generalize via Recursion</li>
<li>[] DSD: Dense-Sparse-Dense Training for Deep Neural Networks</li>

<li><p>[] Introspection:Accelerating Neural Network Training By Learning Weight Evolution</p></li>

<li><p>[]</p></li>

<li><p>Incremental Growth of Semantic Branches on CNNs via Multi-Shot Learning Quanshi Zhang, Ruiming Cao, Ying Nian Wu and Song-Chun Zhu</p></li>

<li><p>Unsupervised Large Graph Embedding Feiping Nie, Wei Zhu and Xuelong Li</p></li>

<li><p>Regularization for Unsupervised Deep Neural Nets Baiyang Wang and Diego Klabjan</p></li>

<li><p>Efficient Hyperparameter Optimization of Deep Learning Algorithms Using Deterministic RBF Surrogates
Ilija Ilievski, Jiashi Feng, Taimoor Akhtar and Christine Shoemaker</p></li>

<li><p>Tunable Sensitivity to Large Errors in Neural Network Training Gil Keren, Sivan Sabato and Björn Schuller</p></li>

<li><p>Understanding the Semantic Structures of Tables with a Hybrid Deep Neural Network Architecture
Kyosuke Nishida, Kugatsu Sadamitsu, Ryuichiro Higashinaka and Yoshihiro Matsuo</p></li>

<li><p><a href="https://arxiv.org/pdf/1606.04474v1.pdf">Learning to learn by gradient descent by gradient descent</a></p></li>
</ul>

<p>Feature engineering - the data you have may have all info that is required by the model, but these
might not be in a mode that can be leveraged.</p>

<h2 id="hyperparameters">Hyperparameters</h2>

<ul>
<li><a href="http://fastml.com/tuning-hyperparams-fast-with-hyperband/">Hyperban by fastml</a></li>
<li><a href="https://people.eecs.berkeley.edu/~kjamieson/hyperband.html">Hyperband at Berkeley</a></li>
</ul>

<h2 id="basic-definitions">Basic Definitions</h2>

<ul>
<li>Affine</li>

<li><p>Deep Learning](<a href="http://neuralnetworksanddeeplearning.com/chap6.html">http://neuralnetworksanddeeplearning.com/chap6.html</a>)</p></li>

<li><p>DL Bells and Wistles:
<a href="http://colinraffel.com/wiki/neural_network_hyperparameters">Nerual Network Hyperparameters</a>
<a href="http://www.iro.umontreal.ca/~bengioy/papers/YB-tricks.pdf">Hyper-Parameters</a></p></li>

<li><p>It has been shown that the use of computer clusters for hyper-parameter selection can have an important effect on results (Pinto et al., 2009).</p></li>

<li><p>We define a hyper-parameter for a learning algorithm A as a value to be selected prior to the ac- tual application of A to the data, a value that is not directly selected by the learning algorithm itself.</p></li>

<li><p>Matrices:
Hessian matrix</p>

<ul>
<li>a square matrix of  second-order paritla derivatives of a scalar-valued function or scalar-field.</li>
</ul></li>

<li><p>Gauss-Newton matrix</p></li>

<li><p>Fisher information matrix</p></li>
</ul>

<h3 id="training-time">Training Time</h3>

<p>What is a long time? So in reference to standard deep learning tasks when working with
standard datasets such as MNIST,</p>

<h3 id="different-nn-architectures">Different NN Architectures</h3>

<ul>
<li><p>On ReLU (rectifying linear unit)</p>

<ul>
<li><a href="https://stats.stackexchange.com/questions/188083/how-to-know-where-to-put-bias-terms-in-neural-nets">Dealing with the bias term in NN</a></li>
<li>See Yoshua Bengio and Yann Dauphin&rsquo;s article Big Neural Networks Waste Capacity, which touches on this issue and explores the diminishing returns issue when constructing bigger or deeper neural networks.</li>
</ul></li>

<li><p>Weigts evolution
This is an interesting concept.</p>

<h2 id="other-interesting-papers">Other Interesting Papers</h2></li>

<li><p><a href="https://github.com/carpedm20/simulated-unsupervised-tensorflow">TensorFlow implementation of &ldquo;Learning from Simulated and Unsupervised Images through Adversarial Training&rdquo;</a></p></li>
</ul>

<h2 id="frameworks">Frameworks</h2>

<ul>
<li><a href="https://www.tensorflow.org/tutorials/deep_cnn">Convolutional Neural Networks</a></li>
</ul>

<h3 id="tensorflow">tensorflow</h3>

<ul>
<li><a href="https://www.matroid.com/dlwithtf/chap1-2.pdf">Getting started with tensorflow</a></li>
<li><a href="https://www.tensorflow.org/install/install_mac#ValidateYourInstallation">validate the installation </a></li>
</ul>

<p>To avoid the warning, let&rsquo;s install tensorflow from source.
* Dependencies
    - <code>brew install bazel</code>
    - <a href="https://docs.bazel.build/versions/master/install-os-x.htmlhttps://docs.bazel.build/versions/master/install-os-x.html">Install Bazel</a>
    Once installe, you can upgrade to a newer version of Bazel with:<code>sudo apt-get upgrade bazel</code></p>

<ul>
<li>Warnings

<ul>
<li>W <code>tensorflow/core/platform/cpu_feature_guard.cc:45</code> The TensorFlow library wasn&rsquo;t compiled to use SSE4.2 instructions</li>
</ul></li>
<li><code>Invalid path to CUDA 8.0 toolkit. /usr/local/cuda/lib/libcudart.8.0.dylib cannot be found</code></li>
</ul>
	</p>

	

		</div>

		<!-- Footer -->
<footer id="footer">
	<ul class="icons">
		
		
		
		<li><a href="//twitter.com/abitofalchemy" target="_blank" class="icon fa-twitter"><span class="label">Twitter</span></a></li>
		
		
		<li><a href="//github.com/abitofalchemy" target="_blank" class="icon fa-github"><span class="label">Github</span></a></li>
		
		
		<li><a href="https://www.linkedin.com/in/saguinag" target="_blank" class="icon fa-linkedin-square"><span class="label">Linkedin</span></a></li>
		
		
		
		
		<li><a href="#contact-form" class="icon fa-envelope-o"><span class="label">Email</span></a></li>
		
	</ul>

	<ul class="copyright">
		
		<li>&copy; S. Aguinaga | Design: <a href="//html5up.net">HTML5 UP</a></li>
		
	</ul>
</footer>

<!-- Scripts -->
<script src="http://s-aguinaga.github.io/js/jquery.min.js"></script>
<script src="http://s-aguinaga.github.io/js/jquery.poptrox.min.js"></script>
<script src="http://s-aguinaga.github.io/js/skel.min.js"></script>
<script src="http://s-aguinaga.github.io/js/util.js"></script>

<script src="http://s-aguinaga.github.io/js/main.js"></script>


<script>
window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;
ga('create', 'UA-35842456-1', 'auto');
ga('send', 'pageview');
</script>
<script async src='//www.google-analytics.com/analytics.js'></script>




	</body>
</html>
